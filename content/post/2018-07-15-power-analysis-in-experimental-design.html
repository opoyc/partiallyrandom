---
title: Power analysis in experimental design
author: Obryan Poyser
date: '2018-07-15'
slug: power-analysis-in-experimental-design
categories:
  - Statistics
tags:
  - Power Analysis
  - R
  - Experiments
  - Causal inference
type: post
description: ""
keywords:
  - key
  - words
topics:
  - topic 1
bibliography: allrefs.bib
---



<p>A couple of weeks ago we had hour yearly Ph.D. workshop in which we present our project development. I’ve always moral sentiments around my duties regarding what someone like me who received a grant should do. One of these moral burdens is to assist to every single presentation and try to provide useful feedback.</p>
<p>Long story short, a fellow Ph.D. student presented a draft of a experimental design. Aligned with my principles, I suggested her to be more humble regarding what she wanted to test, since there were far too many hypotheses she wanted to test for (i.e. treatments) which certainly would limit her sample within and between groups. As a consequence, she replied: <em>How big do you think my sample should be?</em>, to be honest, I couldn’t provide her with an exact answer, this post is a result of my deficient feedback.</p>
<p>Experiments have been increasing in popularity in economics, as an effect of the “empirical revolution” trending as a whole as well as an increasing criticism on identification assumptions when the objective is to find a causal effect in observational data. Indeed, experiments let us identify a cause for certain phenomena easier, nevertheless, the design as well as the cost of realizing an experiment is not negligible. If something ends bad, most probably we won’t have the same resources and opportunity to rerun it, hence, we must be careful to design an experiment that maximizes our testing expectations.</p>
<p>Finding the optimal sample size is definitely one of the main concerns a researcher should have when she designs an experiment. For this matter, there exist the so-called <strong>Power Analysis</strong>, a process of estimating the minimum (optimal) sample size needed to detect an effect given a treatment at the desired significance level.</p>
<p><span class="citation">List, Sadoff, and Wagner (2011)</span> argue that there are three main aspects we should consider in order to calculate the optimal sample size:</p>
<ol style="list-style-type: decimal">
<li>Significance level</li>
<li>Power</li>
<li>Minimum detectable effect size</li>
</ol>
<p>So, let’s start by talking about significance level, by bringing back what we learned in statistics 101 about hypothesis testing:</p>
<ul>
<li><p>Type I: Probability of rejecting the null hypothesis given that it is true (false positive). Typically, it is referred as significance level <span class="math inline">\(\alpha\)</span> of the hypothesis test. <span class="math display">\[P(R|H_0=true)\]</span></p></li>
<li><p>Type II: Probability of not rejecting (accepting for notational purposes) the null hypothesis given that it is false (false negative). Commonly, this decision error is described as <span class="math inline">\(\beta\)</span>. <span class="math display">\[P(A|H_0=false)\]</span></p></li>
</ul>
<p>The power is defined as the likelihood of correctly rejecting <span class="math inline">\(H_0\)</span> when it was actually false, or <span class="math inline">\(1-\beta=1-P(A|H_0=false)\)</span>. The rule of thumb dictates a power equivalent of <span class="math inline">\(0.80\)</span>. Having all this information, it will be useful demostrate the use of power with an example for a couple of syntethic random variables. Let’s assume we run an experiment to test for the effect of advertising on monthly chocolate consumption, described as two normal distributions with <span class="math inline">\(\mu_1\sim N(40,5)\)</span> and <span class="math inline">\(\mu_2 \sim N(50,5)\)</span> for a control and treatment groups respectively.</p>
<pre class="r"><code>require(tidyverse)
require(ggridges)

set.seed(29)

# Two normal random variables with mean 40 and 50 respectively. 
control &lt;- rnorm(n = 120, 40, sd = 3)
treatment &lt;- rnorm(n = 120, 50, sd = 5)
db &lt;- tibble(control, treatment) %&gt;%
    gather(key = &quot;random_var&quot;, value = &quot;value&quot;)

# Graph
db %&gt;%
ggplot(aes(value, random_var, fill=random_var))+
    geom_density_ridges(alpha=.8)</code></pre>
<p><img src="/post/2018-07-15-power-analysis-in-experimental-design_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>From the graph we can conclude that it is unlikely that the advertising is not affecting chocolate consumption since there is a noticeable difference in the means between the two groups. However, <em>ex-ante</em> in a experiment we would want to know the minimum sample size required to detect the effect of advertising, assuming that we have a good guess of the true parameters.</p>
<p>(it depends on the mean <span class="math inline">\(\mu\)</span>, standard deviation <span class="math inline">\(\sigma\)</span>, observations <span class="math inline">\(n\)</span> and a given significance level <span class="math inline">\(\alpha\)</span>.)</p>
<p>by calculating the values that make the difference significative. Recall that power is the probability of rejecting the null hypothesis when it is actually false. Moreover, it depends on the mean <span class="math inline">\(\mu\)</span>, standard deviation <span class="math inline">\(\sigma\)</span>, observations <span class="math inline">\(n\)</span> and a given significance level <span class="math inline">\(\alpha\)</span>.</p>
<p>How many chocolates are neccesary to be consumed in order to reject the null hypothesis that <span class="math inline">\(H_0=40\)</span>?</p>
<p>We know that at a significance level <span class="math inline">\(\alpha=0.05\)</span> the Z-score is <span class="math inline">\(1.96\)</span>, therefore we are looking for values that fall in the rejection region, that is: <span class="math display">\[
\begin{align}
Z\leq &amp; -1.96 \\
Z\geq &amp; 1.96
\end{align}
\]</span> From the Z-score function we are able to calculate the minimum values of <span class="math inline">\(\bar{X}\)</span> in order to find a statistical significant difference:</p>
<p><span class="math display">\[
\begin{align}
\frac{\bar{X}-\mu}{\sigma} &amp; \leq -1.96 &amp; \frac{\bar{X}-\mu}{\sigma} &amp; \geq 1.96 \\
\newline
\frac{\bar{X}-40}{3} &amp; \leq -1.96 &amp; \frac{\bar{X}-40}{3} &amp; \geq 1.96 \\
\end{align}
\]</span></p>
<p>As a result the treatment average has to be either <span class="math inline">\(\bar{X} \leq\)</span> 33.495 or <span class="math inline">\(\bar{X} \geq\)</span> 45.919 in order to be statistically different from 40.</p>
<pre class="r"><code>minF &lt;- function(x){
    low &lt;- -1.96*sd(x)/sqrt(length(x))+mean(x)
    up &lt;- 1.96*sd(x)/sqrt(length(x))+mean(x)
    return(c(low, up))
}

min2F &lt;- function(mean, sd, n){
    low &lt;- -1.96*sd/sqrt(n)+mean
    up &lt;- 1.96*sd/sqrt(n)+mean
    return(c(low, up))
}</code></pre>
<pre class="r"><code>db %&gt;%
    filter(random_var==&quot;control&quot;) %&gt;%
    ggplot(aes(value))+
    geom_density(fill=&quot;black&quot;, alpha=.6)+
    scale_x_continuous(limits = c(29,50))+
    geom_vline(xintercept = c(33.4953796, 45.9189023), colour=&quot;red&quot;)</code></pre>
<p><img src="/post/2018-07-15-power-analysis-in-experimental-design_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>let’s start by calculating the Z-Scores for <code>r1</code></p>
<pre class="r"><code>zF=function(x){
    z=(x-mean(x))/(sd(x)^2/sqrt(length(x)))
    return(z)
}</code></pre>
<pre class="r"><code>test &lt;- rnorm(n = 120, 39, sd = 3) %&gt;%
tibble(v1=., v2=db$value[db$random_var==&quot;control&quot;]) %&gt;% 
    gather()
t.test(test$value~test$key)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  test$value by test$key
## t = -2.5423, df = 237.46, p-value = 0.01165
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -1.8917160 -0.2399219
## sample estimates:
## mean in group v1 mean in group v2 
##         38.64132         39.70714</code></pre>
<p>For now, Suppose <span class="math inline">\(\delta\)</span> is the difference between the outcome of both subsamples, in other words <span class="math inline">\(\delta=\mu_1-\mu_2\)</span>. Typically, the null hypothesis <span class="math inline">\(H_0\)</span> is that there are no difference between groups (<span class="math inline">\(\delta=0\)</span>), while the alternative hypothesis <span class="math inline">\(H_1\)</span>.</p>
<p>In order to estimate the difference, we are going to use the independent t-test given by a formula:</p>
<p><span class="math display">\[
t=\frac{\mu_1-\mu_2}{\sqrt{\frac{S_1^2}{N_1}+\frac{S_2^2}{N_2}}}
\]</span></p>
<pre class="r"><code>db %&gt;%
    group_by(random_var) %&gt;%
    summarise(mean(value), sd(value), n())</code></pre>
<pre><code>## # A tibble: 2 x 4
##   random_var `mean(value)` `sd(value)` `n()`
##   &lt;chr&gt;              &lt;dbl&gt;       &lt;dbl&gt; &lt;int&gt;
## 1 control             39.7        3.17   120
## 2 treatment           50.0        5.37   120</code></pre>
<p><span class="math display">\[
t=\frac{39.99648-49.99105}{\sqrt{25/100000+25/100000}}=-447
\]</span> Which can be calculated directly by:</p>
<pre class="r"><code>t.test(db$value~db$random_var, alternative=&quot;two.sided&quot;, var.equal=F)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  db$value by db$random_var
## t = -18.104, df = 192.93, p-value &lt; 2.2e-16
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -11.427904  -9.182467
## sample estimates:
##   mean in group control mean in group treatment 
##                39.70714                50.01233</code></pre>
<div id="references" class="section level3 unnumbered">
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-List2011">
<p>List, John A, Sally Sadoff, and Mathis Wagner. 2011. “So you want to run an experiment, now what? Some simple rules of thumb for optimal experimental design.” <em>Experimental Economics</em> 14 (4): 439–57. doi:<a href="https://doi.org/10.1007/s10683-011-9275-7">10.1007/s10683-011-9275-7</a>.</p>
</div>
</div>
</div>
