---
title: Power analysis in experimental design
author: Obryan Poyser
date: '2018-07-15'
slug: power-analysis-in-experimental-design
categories:
  - Statistics
tags:
  - Power Analysis
  - R
type: post
description: ""
keywords:
  - key
  - words
topics:
  - topic 1
bibliography: allrefs.bib
---



<p>A couple of weeks ago we had hour yearly Ph.D. workshop in which we present our project development. I’ve always moral sentiments around my duties regarding what someone as me who received a grant should do. One of these moral burden is to assist to every single presentation and try to provide useful feedback.</p>
<p>Long story short, a fellow Ph.D. student presented a draft of a experimental design. Aligned with my principles, I suggested her to be more humble regarding what she wanted to test, since there were far too many hypothesis she wanted to test for (i.e. treatments) which certainly would limit her sample within and between groups. As a consequence, she replied: <em>How big do you think my sample should be?</em>, to be honest, I couldn’t provide her with a exact answer, this post is a result of my deficient feedback.</p>
<p>Experiments have been increasing in popularity in economics, as a effect of the “empirical revolution” trending as a whole as well as an increasing criticism on identification assumptions when the objective is to find a causal effect in observational data. Indeed, experiments let us identify a cause for a certain phenomena easier, nevertheless, the design as well as the cost of realizing a experiment is not negligible. If something ends bad, most probably we won’t have the same resources and opportunity to rerun it, hence, we must be careful to design an experiment that maximize our testing expectatives.</p>
<p>Finding the optimal sample size is definitely one of the main concerns a researcher should have when she designs an experiment. For this matter, there exist the so-called <strong>Power Analysis</strong>, a process of estimating the minimum (optimal) sample size needed to detect an effect given a treatment at a desirable significance level.</p>
<p><span class="citation">List, Sadoff, and Wagner (2011)</span> argue that there are three main aspects we should consider in order to calculate the optimal sample size.</p>
<ol style="list-style-type: decimal">
<li>Significance level</li>
<li>Power</li>
<li>Minimum detectable effect size</li>
</ol>
<p>So, let’s start by talking about significance level, by bringing back what we learned in statistics 101 about hypothesis testing:</p>
<ul>
<li>Type I: Probability of rejecting the null hypothesis when it is true (false positive)<br />
<span class="math display">\[P()\]</span></li>
<li>Type II: Probability of not rejecting (accepting duh) the null hypothesis when it is false (false negative)</li>
</ul>
<p>and Type II error described by:</p>
<div id="refs" class="references">
<div id="ref-List2011">
<p>List, John A, Sally Sadoff, and Mathis Wagner. 2011. “So you want to run an experiment, now what? Some simple rules of thumb for optimal experimental design.” <em>Experimental Economics</em> 14 (4): 439–57. doi:<a href="https://doi.org/10.1007/s10683-011-9275-7">10.1007/s10683-011-9275-7</a>.</p>
</div>
</div>
